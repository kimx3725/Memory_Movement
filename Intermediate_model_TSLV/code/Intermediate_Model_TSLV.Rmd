---
title: "1.amt_conv"
author: "Dennis Kim"
date: "2022-10-06"
output: html_document
---

# Objective 

To explore the structure of the bear data set. To do this, I will: 

1. Generate used and available locations of the bear through amt framework. 
2. Extract habitat covariate from habitat layer. 
3. Create a sf polygon per each step length representing a buffer 
4. Calculate the points that fall within each buffer and count the number of locations that revisited 
5. Similar to Uli's paper, the locations that are visited to each buffer will count as 0, otherwise +1 
6. Include TSLV values per each observations throughtout the time and save them in the column of the data 
7. Fit SSF model with a TSLV predictor 

## Document Preamble 
```{r preamble, include = FALSE}
# load libraries
library(knitr)
library(dplyr)
library(readr)
library(data.table)
library(DT)
library(here)
library(stringr)
library(tidyr)
library(purrr)
library(amt)
library(ggplot2)
library(raster)
library(sf)
library(recurse)
library(scales)
library(sp)
library(geosphere)
library(generics)
library(sfheaders)
library(lubridate)
library(pastecs)
library(stats)
library(mapview)
library(tmap)
library(spatialEco)
library(paletteer)
library(wesanderson)
library(doBy)
library(stars)
options(width = 150)

# set knitr options 
opts_chunk$set(fig.width = 6, fig.height = 5, comment = NA)
```

## Tracking data 

Read in the gps data 
```{r read gps data}
# Location data of the bear 
bear <- read.csv(here::here("data", "GF1143_raw.csv"))

# change the time format of the data 
bear$datetime <- as.POSIXct(bear$datetime, format =  "%Y-%m-%d %H:%M")

# summary of the data
summary(bear)
```

Plot the data 
```{r bear location vis}
ggplot(bear, aes(x = x, y = y))+ 
  geom_point()
```

## Prepare environmental data 

Add environmental covariate (berry)
```{r habitat layer}
# call the berries layer
berry <- raster(here("data/berries/berries.tif"))

# plot the layer
plot(berry)

# crs of the layer 
crs(berry)
```


## amt conversion 

Add a track class to the data and summarize the data 
```{r amt conversion}
# make tracks 
trk.bear <- amt::make_track(bear, .x=x, .y=y, .t=datetime, crs=CRS("+init=epsg:26908"))

summary(trk.bear)
```

Summarize the sampling rates of the bear
```{r sampling rates}
# 4 hour sampling seems reasonable - no need to resample - since it is already resampled 
summarize_sampling_rate(trk.bear) 
```

change the track point to step 
1. Resample track and filter bursts 
2. Convert track to steps 
3. Create random steps 
4. Extract covariate values 
```{r retrk bear}
# follow the above approach 
ssfdat.bear <- 
  trk.bear %>% track_resample(rate = hours(4), tolerance = minutes(30)) %>% 
  steps_by_burst() %>% 
  random_steps(n_control = 5) %>% 
  extract_covariates(berry) %>% 
  filter(!is.na(ta_))

# summary of the ssf data
summary(ssfdat.bear)
```

Check the reasonable buffer distance for each step length - I will pick 1000m as a buffer distance from the step lengths 
```{r sl distribution}
ssfdat.bear %>% filter(case_ == "TRUE") %>% dplyr::select(sl_) %>% summary()
```

## Create observation points

select randomized and used locations of the tracks from the ssfdat.bear
```{r st points}
# select random locations that matched with observed step lengths 
obs <- ssfdat.bear %>% filter(case_ == TRUE)
ran <- ssfdat.bear %>% filter(case_ == FALSE)

# select observed locations
obs.loc <- obs %>% dplyr::select(x1_, y1_)
colnames(obs.loc) <- c("x", "y")
obs.loc.sf <- st_as_sf(obs.loc, coords = c("x", "y"), crs = "+proj=utm +zone=8 +datum=NAD83 +units=m +no_defs")
obs.loc %>% head()

## mapview
#mapview(obs.loc.sf, cex = 3, alpha = 0.5, popup = NULL)

# select random locations
ran.loc <- ran %>% dplyr::select(x2_, y2_)
colnames(ran.loc) <- c("x", "y")
ran.loc.sf <- st_as_sf(ran.loc, coords = c("x", "y"), crs = "+proj=utm +zone=8 +datum=NAD83 +units=m +no_defs")
ran.loc %>% head()

## mapview
#mapview(ran.loc.sf, cex = 3, alpha = 0.5, popup = NULL)
```

## create a temporal spatial cognitive map 

we will first create a grid which the extent equals to the bounding box of the selected points
```{r grid cells}
# create 2000m x 2000m grid cell in the map (24 x 20)
memory.map = st_make_grid(obs.loc.sf, c(2000, 2000), what = "polygons", square = TRUE)
memory.map

# convert the map to sf object
memory.map.sf = st_sf(memory.map)

# plot the map
memory.map.sf %>% plot()
```

## Time Since Last Vitist (TSLV)

Follow Uli's approach: Their definition of TSLV is short and sweet (see equation 4 in that paper) - basically, it's 0 if the point in question is within some distance Î´ (this value could be similar to the value you used for your buffer) of the previous point, and otherwise it's (previous TSLV + 1). So they define it iteratively, starting at the first point and iteratively updating TSLV with each time step.


### Observed Locations 

Burn-in phase
```{r}
# create a burn in list 
burnin.obs.list <- list()
burnin.obs.ras.list <- list()

# for first 100 phase 
for(i in 1:100){
# calculate the animal's visitation to a each grid cell (1 indicates animal visited that particular grid, otherwise 0)  
burnin.obs.list[[i]] <- memory.map.sf %>% mutate(visit = lengths(st_intersects(memory.map.sf, obs.loc.sf[i,1])))

# convert to raster
burnin.obs.ras.list[[i]] <- burnin.obs.list[[i]] %>% raster(ncol= 20, nrow = 24)

# insert the visited value per each raster map
values(burnin.obs.ras.list[[i]]) <- burnin.obs.list[[i]]$visit
}

burnin.obs.ras.list[[1]] %>% plot()
```

Write function to calculate run length to specified value. If the specified run value (y) is the first value it returns a 0 and if it is missing then a NA is returned.
```{r tslv}
# tslv function
time.since.last.visit <- function(x, y=1, dir=c("LR", "RL")) {
    if(dir[1] == "RL") x <- rev(x)
    # compute the lengths and values of runs of equal values in a vector -- or the reverse operation
      x.idx <- rle(x)$values
      v.idx <- rle(x)$lengths 
    # if the x is equal to y (1) visited   
    if(x[1] == y) {
      # then equal to 0
      v <- 0
    } else {
      v <- v.idx[which(x.idx == y)-1][1]
    }   
  return( v )
}

# stack all the raster layers: each layer will have a value of one observation at time t 
r = raster::brick(burnin.obs.ras.list)
# calculate tslv 
(tslv1 <- calc(r, fun=time.since.last.visit))

# plot the tslv values 
tslv1 %>% plot()


#Now, apply it to a raster stack example
memory.map.sf <- memory.map.sf %>% mutate(tslv = values(t2e)) 
memory.map.sf %>% data.frame()
```



```{r obs: count grid}
# count number odfpoints in each grid
# https://gis.stackexchange.com/questions/323698/counting-points-in-polygons-with-sf-package-of-r
bear.sp.tmp.map.sf$visit = lengths(st_intersects(bear.sp.tmp.map.sf, obs.loc.sf))

bear.ini.memory.map <- bear.sp.tmp.map.sf %>% mutate(tslv = ifelse(visit == 1, 0, NA)) %>% as.data.frame() %>% mutate(tslv = values(t2e))
bear.ini.memory.map
```

To check the result, plot the grid into a interactive thematic map with tmap.
```{r, obs:grid map}
tmap_mode("view")

map_fishnet_obs = tm_shape(fishnet_grid_sf_obs) +
  tm_fill(
    col = "obs_n_colli",
    palette = "Reds",
    style = "cont",
    title = "Number of Observed point revisited",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.5,
    popup.vars = c(
      "Number of revisitations: " = "obs_n_colli"
    ),
    popup.format = list(
      obs_n_colli = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.7)

map_fishnet_obs
```

convert geometry back to lat and long
```{r obs:geom to latlong}
# extract observation locations that fall into the grid
obs.tslv <- point.in.poly(obs.loc.sf, bear.sp.tmp.map.sf) %>% as.data.frame() 
obs.tslv

bear.sp.tmp.map.sf %>% as.data.frame()
```

### Random Locations 

*[Do the exact same framework as above]*
Then count the number of revisitations from observed locations
```{r ran: count grid}
# count number of points in each grid
# https://gis.stackexchange.com/questions/323698/counting-points-in-polygons-with-sf-package-of-r
fishnet_grid_sf_ran$ran_n_colli = lengths(st_intersects(fishnet_grid_sf_ran, ran.loc.sf))

# remove grid without value of 0 (i.e. no points in side that grid)
fishnet_grid_sf_ran
```

To check the result, plot the grid into a interactive thematic map with tmap.
```{r, ran:grid map, }
tmap_mode("view")

map_fishnet_ran = tm_shape(fishnet_grid_sf_ran) +
  tm_fill(
    col = "ran_n_colli",
    palette = "Reds",
    style = "cont",
    title = "Number of random point revisited",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.5,
    popup.vars = c(
      "Number of revisitations: " = "ran_n_colli"
    ),
    popup.format = list(
      ran_n_colli = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.7)

map_fishnet_ran
```

convert geometry back to lat and long
```{r ran:geom to latlong}
# extract observation locations that fall into the grid
ran.tslv <- point.in.poly(ran.loc.sf, fishnet_grid_sf_ran) %>% as.data.frame() %>%
# create a column called tslv and set 0 for all as a start point
  mutate(tslv = 0) %>% 
# calculate the time between the last visit to the location and the beginning of the actual trajectory   
  mutate(tslv1 = grid_id - lag(grid_id, default = first(grid_id))) 

# only filter out those who visited during the initial phase 
ini.ran <- ran.tslv %>% filter(grid_id < 100)

# only filter out those who never visited during the initial phase 
# for the first row, subtract by the length of the initialization phase (100)
aft.ini.ran <- ran.tslv %>% filter(grid_id > 100) %>% mutate(tslv1 = ifelse(row_number() == 1, grid_id - 100, tslv1))

# rbind the modified initial phase and after ranervations and make sure to have absolute value  
final.ran.tslv <- rbind(ini.ran, aft.ini.ran) %>% abs() %>% dplyr::select(-tslv)
# change the colnames 
colnames(final.ran.tslv) <- c("observation.id", "timestep.visited", "n.revisitation", "x2_", "y2_", "TSLV")
# you can see there is an NA values in TSLV which means we have missing observations so there are areas that are almost surely used but where tslv does not get updated due to a gap in the data 

# we will be calculating the tslv to minimize this gap 
final.ran.tslv <- final.ran.tslv %>% 
  # calculate the time between the last visit to the location and the beginning of the actual trajectory   
  mutate(tslv1 = replace_na(TSLV, 0)) %>% 
  mutate(TSLV = timestep.visited - lag(timestep.visited, default = first(timestep.visited))) %>% 
  dplyr::select(-tslv1) %>% abs()

final.ran.tslv %>% head()
```

### Merge the data

include tslv information to the original data
```{r amt tslv}
# extract updated tslv values per observed and random locations 
obs.loc.TSLV <- final.obs.tslv %>% mutate(case_ = TRUE) %>% dplyr::select(-c(observation.id, timestep.visited, n.revisitation))
obs.loc.TSLV %>% head()

ran.loc.TSLV <- final.ran.tslv %>% mutate(case_ = FALSE) %>% dplyr::select(-c(observation.id, timestep.visited, n.revisitation))
ran.loc.TSLV %>% head()

# select ssfdat filtered by TRUE and extract the tslv values 
ssfdat.bear.true <- ssfdat.bear %>% filter(case_ == TRUE)
ssfdat.bear.true1 <- ssfdat.bear.true %>% left_join(., obs.loc.TSLV, by = c("x1_", "y1_", "case_")) 

# same for false  
ssfdat.bear.false <- ssfdat.bear %>% filter(case_ == FALSE)
ssfdat.bear.false1 <- ssfdat.bear.false %>% left_join(., ran.loc.TSLV, by = c("x2_", "y2_", "case_")) 

# as you can tell, there is NA tslv values in available step lengths - this indicates that they are not generated from the observed locations - so we would like to omit them here as well. 
ssfdat.bear.false1 <- ssfdat.bear.false1 %>% filter(complete.cases(TSLV))

# brind all the rows of both used and available locations with tslv information 
ssfdat.bear.final <- rbind(ssfdat.bear.true1, ssfdat.bear.false1) 
ssfdat.bear.final %>% summary()

ssfdat.bear.final

# save the data 
#write_rds(ssfdat.bear.final, path = here("data", "ssfdat_final_tslv.Rdata"))
```

TSLV visualization
```{r TSLV visualization}
# overall plot - there is a few steps that has really long TSLV values than the others 
ssfdat.bear.final %>% filter(step_id_ > 100 & case_==1) %>% ggplot(., aes(x = x1_, y = y1_, col = TSLV))+
  geom_point(size=2)+geom_path() +
  scale_color_gradient2(low = "yellow", mid = "darkblue", high = "red") +
  theme_void()

# zoom-in
ssfdat.bear.final %>% filter(step_id_ > 100 & case_==1) %>% ggplot(., aes(x = x1_, y = y1_, col = TSLV))+
  geom_point(size=2)+geom_path() +
  scale_color_gradient2(low = "yellow", mid = "darkblue", high = "red", limits = c(0, 500)) +
  theme_void()
```


## FitSSF
```{r fit ssf}
# only resource predictor 
ssfdat.bear.final %>% slice(101:n()) %>% amt::fit_issf(case_ ~ berries+ log(sl_)+ cos(ta_)+ strata(step_id_)) %>% summary()

# TSLV predictor included
ssfdat.bear.final %>% slice(101:n()) %>% amt::fit_issf(case_ ~ berries+ TSLV+ log(sl_)+ cos(ta_)+ strata(step_id_)) %>% summary()

# Interaction between TSLV and berries
ssfdat.bear.final %>% slice(101:n()) %>% amt::fit_issf(case_ ~ berries+ TSLV+ TSLV:berries+ log(sl_)+ cos(ta_)+ strata(step_id_)) %>% summary()
```

## Footer
```{r footer}
sessionInfo()
```