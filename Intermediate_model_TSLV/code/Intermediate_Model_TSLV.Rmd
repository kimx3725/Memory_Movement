---
title: "1.amt_conv"
author: "Dennis Kim"
date: "2022-10-06"
output: html_document
---

# Objective 

To explore the structure of the bear data set. To do this, I will: 

1. Generate used and available locations of the bear through amt framework. 
2. Extract habitat covariate from habitat layer. 
3. Create a sf polygon per each step length representing a buffer 
4. Calculate the points that fall within each buffer and count the number of locations that revisited 
5. Similar to Uli's paper, the locations that are visited to each buffer will count as 0, otherwise +1 
6. Include TSLV values per each observations throughtout the time and save them in the column of the data 
7. Fit SSF model with a TSLV predictor 

## Document Preamble 
```{r preamble, include = FALSE}
# load libraries
library(knitr)
library(dplyr)
library(readr)
library(data.table)
library(DT)
library(here)
library(stringr)
library(tidyr)
library(purrr)
library(amt)
library(ggplot2)
library(raster)
library(sf)
library(recurse)
library(scales)
library(sp)
library(geosphere)
library(generics)
library(sfheaders)
library(lubridate)
library(pastecs)
library(stats)
library(mapview)
library(tmap)
library(spatialEco)
options(width = 150)

# set knitr options 
opts_chunk$set(fig.width = 6, fig.height = 5, comment = NA)
```

## Tracking data 

Read in the gps data 
```{r read gps data}
# Location data of the bear 
bear <- read.csv(here::here("data", "GF1143_raw.csv"))

# change the time format of the data 
bear$datetime <- as.POSIXct(bear$datetime, format =  "%Y-%m-%d %H:%M")

# summary of the data
summary(bear)
```

Plot the data 
```{r bear location vis}
ggplot(bear, aes(x = x, y = y))+ 
  geom_point()
```

## Prepare environmental data 

Add environmental covariate (berry)
```{r habitat layer}
# call the berries layer
berry <- raster(here("data/berries/berries.tif"))

# plot the layer
plot(berry)

# crs of the layer 
crs(berry)
```


## amt conversion 

Add a track class to the data and summarize the data 
```{r amt conversion}
# make tracks 
trk.bear <- amt::make_track(bear, .x=x, .y=y, .t=datetime, crs=CRS("+init=epsg:26908"))

summary(trk.bear)
```

Summarize the sampling rates of the bear
```{r sampling rates}
# 4 hour sampling seems reasonable - no need to resample - since it is already resampled 
summarize_sampling_rate(trk.bear) 
```

change the track point to step 
1. Resample track and filter bursts 
2. Convert track to steps 
3. Create random steps 
4. Extract covariate values 
```{r retrk bear}
# follow the above approach 
ssfdat.bear <- 
  trk.bear %>% track_resample(rate = hours(4), tolerance = minutes(30)) %>% 
  steps_by_burst() %>% 
  random_steps(n_control = 5) %>% 
  extract_covariates(berry) %>% 
  filter(!is.na(ta_))

# summary of the ssf data
summary(ssfdat.bear)
```

Check the reasonable buffer distance for each step length - I will pick 500m as a buffer distance from the step lengths 
```{r sl distribution}
ssfdat.bear %>% filter(case_ == "TRUE") %>% dplyr::select(sl_) %>% summary()
```

## Create observation points

select randomized and used locations of the tracks from the ssfdat.bear
```{r st points}
# select random locations that matched with observed step lengths 
obs <- ssfdat.bear %>% filter(case_ == TRUE)
ran <- ssfdat.bear %>% filter(case_ == FALSE)

# select observed locations
obs.loc <- obs %>% dplyr::select(x1_, y1_)
colnames(obs.loc) <- c("x", "y")
obs.loc.sf <- st_as_sf(obs.loc, coords = c("x", "y"), crs = "+proj=utm +zone=8 +datum=NAD83 +units=m +no_defs")
obs.loc.sf %>% head()

## mapview
mapview(obs.loc.sf, cex = 3, alpha = 0.5, popup = NULL)

# select random locations
ran.loc <- ran %>% dplyr::select(x2_, y2_)
colnames(ran.loc) <- c("x", "y")
ran.loc.sf <- st_as_sf(ran.loc, coords = c("x", "y"), crs = "+proj=utm +zone=8 +datum=NAD83 +units=m +no_defs")
ran.loc.sf %>% head()

## mapview
mapview(ran.loc.sf, cex = 3, alpha = 0.5, popup = NULL)
```

## create a square grid 

we will first create a grid which the extent equals to the bounding box of the selected points
```{r grid cells}
# create 1000m x 1000m grid cell in the map 
area_bear_visit_grid = st_make_grid(obs.loc.sf, c(1000, 1000), what = "polygons", square = TRUE)
area_bear_visit_grid

# To sf and add grid ID
fishnet_grid_sf = st_sf(area_bear_visit_grid) %>%
  # add grid ID
  mutate(grid_id = 1:length(lengths(area_bear_visit_grid)))

# create a grid sf for observed and random 
fishnet_grid_sf_obs <- fishnet_grid_sf
fishnet_grid_sf_ran <- fishnet_grid_sf
```
## Time Since Last Vitist (TSLV)

Follow Uli's approach: Their definition of TSLV is short and sweet (see equation 4 in that paper) - basically, it's 0 if the point in question is within some distance Î´ (this value could be similar to the value you used for your buffer) of the previous point, and otherwise it's (previous TSLV + 1). So they define it iteratively, starting at the first point and iteratively updating TSLV with each time step.

### Observed Locations 
Then count the number of revisitations from observed locations
```{r obs: count grid}
# count number of points in each grid
# https://gis.stackexchange.com/questions/323698/counting-points-in-polygons-with-sf-package-of-r
fishnet_grid_sf_obs$obs_n_colli = lengths(st_intersects(fishnet_grid_sf_obs, obs.loc.sf))

# remove grid without value of 0 (i.e. no points in side that grid)
fishnet_grid_sf_obs
```

To check the result, plot the grid into a interactive thematic map with tmap.
```{r, obs:grid map}
tmap_mode("view")

map_fishnet_obs = tm_shape(fishnet_grid_sf_obs) +
  tm_fill(
    col = "obs_n_colli",
    palette = "Reds",
    style = "cont",
    title = "Number of Observed point revisited",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.5,
    popup.vars = c(
      "Number of revisitations: " = "obs_n_colli"
    ),
    popup.format = list(
      obs_n_colli = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.7)

map_fishnet_obs
```

convert geometry back to lat and long
```{r obs:geom to latlong}
# extract observation locations that fall into the grid
obs.tslv <- point.in.poly(obs.loc.sf, fishnet_grid_sf_obs) %>% as.data.frame() %>% 
# create a column called tslv and set 0 for all as a start point
  mutate(tslv = 0) %>% 
# calculate the time between the last visit to the location and the beginning of the actual trajectory   
  mutate(tslv1 = grid_id - lag(grid_id, default = first(grid_id))) 

# only filter out those who visited during the initial phase 
ini.obs <- obs.tslv %>% filter(grid_id < 100)

# only filter out those who never visited during the initial phase 
# for the first row, subtract by the length of the initialization phase (100)
aft.ini.obs <- obs.tslv %>% filter(grid_id > 100) %>% mutate(tslv1 = ifelse(row_number() == 1, grid_id - 100, tslv1))

# rbind the modified initial phase and after observations and make sure to have absolute value  
final.obs.tslv <- rbind(ini.obs, aft.ini.obs) %>% abs() %>% dplyr::select(-tslv)
# change the colnames 
colnames(final.obs.tslv) <- c("observation.id", "timestep.visited", "n.revisitation", "x1_", "y1_", "TSLV")
final.obs.tslv %>% head()
```
### Random Locations 

*[Do the exact same framework as above]*
Then count the number of revisitations from observed locations
```{r ran: count grid}
# count number of points in each grid
# https://gis.stackexchange.com/questions/323698/counting-points-in-polygons-with-sf-package-of-r
fishnet_grid_sf_ran$ran_n_colli = lengths(st_intersects(fishnet_grid_sf_ran, ran.loc.sf))

# remove grid without value of 0 (i.e. no points in side that grid)
fishnet_grid_sf_ran
```

To check the result, plot the grid into a interactive thematic map with tmap.
```{r, ran:grid map}
tmap_mode("view")

map_fishnet_ran = tm_shape(fishnet_grid_sf_ran) +
  tm_fill(
    col = "ran_n_colli",
    palette = "Reds",
    style = "cont",
    title = "Number of random point revisited",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.5,
    popup.vars = c(
      "Number of revisitations: " = "ran_n_colli"
    ),
    popup.format = list(
      ran_n_colli = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.7)

map_fishnet_ran
```

convert geometry back to lat and long
```{r ran:geom to latlong}
# extract observation locations that fall into the grid
ran.tslv <- point.in.poly(ran.loc.sf, fishnet_grid_sf_ran) %>% as.data.frame() %>%
# create a column called tslv and set 0 for all as a start point
  mutate(tslv = 0) %>% 
# calculate the time between the last visit to the location and the beginning of the actual trajectory   
  mutate(tslv1 = grid_id - lag(grid_id, default = first(grid_id))) 

# only filter out those who visited during the initial phase 
ini.ran <- ran.tslv %>% filter(grid_id < 100)

# only filter out those who never visited during the initial phase 
# for the first row, subtract by the length of the initialization phase (100)
aft.ini.ran <- ran.tslv %>% filter(grid_id > 100) %>% mutate(tslv1 = ifelse(row_number() == 1, grid_id - 100, tslv1))

# rbind the modified initial phase and after ranervations and make sure to have absolute value  
final.ran.tslv <- rbind(ini.ran, aft.ini.ran) %>% abs() %>% dplyr::select(-tslv)
# change the colnames 
colnames(final.ran.tslv) <- c("observation.id", "timestep.visited", "n.revisitation", "x2_", "y2_", "TSLV")
# you can see there is an NA values in TSLV which means we have missing observations so there are areas that are almost surely used but where tslv does not get updated due to a gap in the data 

# we will be calculating the tslv to minimize this gap 
final.ran.tslv <- final.ran.tslv %>% 
  # calculate the time between the last visit to the location and the beginning of the actual trajectory   
  mutate(tslv1 = replace_na(TSLV, 0)) %>% 
  mutate(TSLV = timestep.visited - lag(timestep.visited, default = first(timestep.visited))) %>% 
  dplyr::select(-tslv1) %>% abs()

final.ran.tslv %>% head()
```

### Merge the data

include tslv information to the original data
```{r amt tslv}
# extract updated tslv values per observed and random locations 
obs.loc.TSLV <- final.obs.tslv %>% mutate(case_ = TRUE) %>% dplyr::select(-c(observation.id, timestep.visited, n.revisitation))
obs.loc.TSLV %>% head()

ran.loc.TSLV <- final.ran.tslv %>% mutate(case_ = FALSE) %>% dplyr::select(-c(observation.id, timestep.visited, n.revisitation))
ran.loc.TSLV %>% head()

# select ssfdat filtered by TRUE and extract the tslv values 
ssfdat.bear.true <- ssfdat.bear %>% filter(case_ == TRUE)
ssfdat.bear.true1 <- ssfdat.bear.true %>% left_join(., obs.loc.TSLV, by = c("x1_", "y1_", "case_")) 

# same for false  
ssfdat.bear.false <- ssfdat.bear %>% filter(case_ == FALSE)
ssfdat.bear.false1 <- ssfdat.bear.false %>% left_join(., ran.loc.TSLV, by = c("x2_", "y2_", "case_")) 

# as you can tell, there is NA tslv values in available step lengths - this indicates that they are not generated from the observed locations - so we would like to omit them here as well. 
ssfdat.bear.false1 <- ssfdat.bear.false1 %>% filter(complete.cases(TSLV))

# brind all the rows of both used and available locations with tslv information 
ssfdat.bear.final <- rbind(ssfdat.bear.true1, ssfdat.bear.false1) 
ssfdat.bear.final %>% summary()

# save the data 
#write_rds(ssfdat.bear.final, path = here("data", "ssfdat_final_tslv.Rdata"))
```
## FitSSF
```{r fit ssf}
# only resource predictor 
ssfdat.bear.final %>% slice(101:n()) %>% amt::fit_issf(case_ ~ berries+ log(sl_)+ cos(ta_)+ strata(step_id_)) %>% summary()

# TSLV predictor included
ssfdat.bear.final %>% slice(101:n()) %>% amt::fit_issf(case_ ~ berries+ TSLV+ log(sl_)+ cos(ta_)+ strata(step_id_)) %>% summary()

# Interaction between TSLV and berries
ssfdat.bear.final %>% slice(101:n()) %>% amt::fit_issf(case_ ~ berries+ TSLV+ TSLV:berries+ log(sl_)+ cos(ta_)+ strata(step_id_)) %>% summary()
```

## Footer
```{r footer}
sessionInfo()
```