---
title: "1.amt_conv"
author: "Dennis Kim"
date: "2022-10-06"
output: html_document
---

# Objective 

To explore the structure of the wolf data set. To do this, I will: 

1. Generate used and available locations of the wolf through amt framework. 
2. Extract habitat covariate from habitat layer. 
3. Create sf polygons that define the buffer of each grid 
4. Calculate the points that fall within each buffer and save it as each raster layer 
5. Calculate the TSLV similar to Uli's approach 
6. Apply it to the different 3 TSLV approaches
7. Include TSLV values per each location and save them in the column of the data 
8. Fit SSF model with a TSLV predictor 

## Document Preamble 
```{r preamble, include = FALSE}
# load libraries
library(knitr)
library(dplyr)
library(readr)
library(data.table)
library(DT)
library(here)
library(stringr)
library(tidyr)
library(purrr)
library(amt)
library(ggplot2)
library(ggnewscale)
library(raster)
library(sf)
library(recurse)
library(scales)
library(sp)
library(geosphere)
library(generics)
library(sfheaders)
library(lubridate)
library(pastecs)
library(stats)
library(tmap)
library(spatialEco)
library(paletteer)
library(wesanderson)
library(doBy)
library(stars)
library(viridis)
library(forcats)
library(splines)
library(lubridate)
library(terra)
library(cowplot)
options(width = 150)

# set knitr options 
opts_chunk$set(fig.width = 6, fig.height = 5, comment = NA)
```

# Data preparation

## Prepare Tracking data 

Read in the gps data 
```{r read gps data}
# Location data of the wolf 
wolf <- read.csv(here::here("data", "wolf220.csv"), header=TRUE)

wolf$date <- gsub('/', '-', wolf$date)
wolf$date <- as.Date(wolf$date, "%m-%d-%Y")

# convert the Actual_Time to PoSIXct format 
wolf$time <- data.table::as.ITime(wolf$time)

# combine the date and time together as a new column - time 
wolf$datetime <- as.POSIXct(paste(wolf$date, wolf$time),
                        format = "%Y-%m-%d %H:%M")

wolf <- wolf %>% dplyr::filter(!is.na(datetime))

wolf %>% summary()
```

Plot the data 
```{r wolf location vis}
ggplot(wolf, aes(x = x, y = y))+ 
  geom_point()
```

## Add Distance to edge of homerange countour

load the environmental layers 
```{r distance to edge}
# distance to edge
dst_edge <- raster(here::here("data", "dist_edge.tif"))
dst_edge

plot(dst_edge)
```


# AMT conversion with habitat predictor 

## amt conversion 

Add a track class to the data and summarize the data 
```{r amt conversion}
# make tracks 
trk.wolf <- amt::make_track(wolf, .x=x, .y=y, .t=datetime, crs=st_crs(4326))

trk.wolf
```

Summarize the sampling rates of the wolf
```{r sampling rates}
# 4 hour sampling seems reasonable - no need to resample - since it is already resampled 
summarize_sampling_rate(trk.wolf) 
```

change the track point to step 
1. Resample track and filter bursts 
2. Convert track to steps 
3. Create random steps (20 random steps)
4. Extract covariate values 
```{r retrk wolf}
# follow the above approach 
# the filtering needs to come before the simulating random points otherwise there will be random points that do not correspond to a use point in the data
ssfdat.wolf <- 
  trk.wolf %>% track_resample(rate = hours(2), tolerance = minutes(15)) %>% 
  steps_by_burst() %>% 
  filter(!is.na(ta_)) %>%
  random_steps(n_control = 20) %>% 
  extract_covariates(dst_edge)

# summary of the ssf data
summary(ssfdat.wolf)
```

Check the reasonable buffer distance for each step length - you can adjust this based on the summary of your step lengths 
```{r sl distribution}
ssfdat.wolf %>% filter(case_ == "TRUE") %>% dplyr::select(sl_) %>% summary()
```

# Spatial temporal cognitive map

select randomized and used locations of the tracks from the ssfdat.wolf for making a map
```{r st points}
# select random locations that matched with observed step lengths 
obs <- ssfdat.wolf %>% filter(case_ == TRUE) # filter the used locations only 
ran <- ssfdat.wolf %>% filter(case_ == FALSE) # filter the random locations only 

# select observed locations
obs.loc <- obs %>% dplyr::select(x1_, y1_) # select the coordinates 
colnames(obs.loc) <- c("x", "y") # change the coordinates names 
obs.loc.sf <- st_as_sf(obs.loc, coords = c("x", "y"), crs = "+proj=utm +datum=NAD83 +units=m +no_defs") # convert the format to sf object 
obs.loc %>% head() # check the head of the converted sf data 

# select random locations (apply the same approaches as above)
ran.loc <- ran %>% dplyr::select(x2_, y2_)
colnames(ran.loc) <- c("x", "y")
ran.loc.sf <- st_as_sf(ran.loc, coords = c("x", "y"), crs = "+proj=utm +datum=NAD83 +units=m +no_defs")
ran.loc %>% head()

# Even if points are not included in the step selection analysis (e.g., because there is a previous data point missing) we must include them in our grid and our subsequent calculation of TSLV, so I have added this extra object that is incorporated into the grid and subsequent steps of the analysis.
all.obs.loc <- trk.wolf %>% dplyr::select(x_, y_)
colnames(all.obs.loc) <- c("x", "y")

# make a spatial points object for the SSF data (use and random points combined). This is important for getting the grid_id for every point from the memory.map.sf grid
ssfdat.wolf.sf.endpoints <- st_as_sf(ssfdat.wolf, coords = c("x2_", "y2_"), crs = "+proj=utm +datum=NAD83 +units=m +no_defs")
```

we will first create a grid which the extent equals to the bounding box of the selected points
```{r memory map}
# create an entire locations as sf including random and observed 
all.loc <- rbind(obs.loc, ran.loc, all.obs.loc) # rbind the observed and random locations together 
all.loc.sf <- st_as_sf(all.loc, coords = c("x", "y"), crs = "+proj=utm +datum=NAD83 +units=m +no_defs") # convert to the sf object 

# create 300m x 300m grid cell in the map 
memory.map = st_make_grid(all.loc.sf, c(300, 300), what = "polygons", square = TRUE)
memory.map # check the grid map 

# convert the map to sf object
memory.map.sf = st_sf(memory.map)

# plot the map
memory.map.sf %>% plot()
memory.map.sf

# : adding grid_id to memory.map.sf so we can get it for all values at the same grid
memory.map.sf$grid_id = 1:nrow(memory.map.sf)
```

Get grid_id values for the SSF data as well as the original, use-only wolf data (which includes some points not included in the step selection analysis but still necessary for accurate TSLV calculation)
```{r grid id values}
# get the grid id for ssf data
ssfdat.grid.id = sf::st_intersection(ssfdat.wolf.sf.endpoints, memory.map.sf) %>% as.data.frame
ssfdat.wolf$grid_id = ssfdat.grid.id$grid_id
ssfdat.wolf

# get the grid id for the original, use-only wolf data
all.obs.loc.sf = st_as_sf(trk.wolf, coords = c("x_", "y_"), crs = "+proj=utm +datum=NAD83 +units=m +no_defs")
all.grid.id = sf::st_intersection(all.obs.loc.sf, memory.map.sf) %>% as.data.frame
trk.wolf$grid_id = all.grid.id$grid_id
trk.wolf
```

## Time Since Last Vitist (TSLV)

Follow Uli's approach: Their definition of TSLV is short and sweet (see equation 4 in their paper) - basically, it's 0 if the point in question is within some distance Î´ (this value could be similar to the value you used for your buffer) of the previous point, and otherwise it's (previous TSLV + 1). So they define it iteratively, starting at the first point and iteratively updating TSLV with each time step.


General approaches: 
1. create a spatial temporal map with the number of cells (for our cases, we use the 300m x 300m buffer).
2. set the burn-in period (60 days - 2 months) - t index would correlate with the number of observation id 
3. calculate the tslv based on the year observations - at the end of the calculation, all the NAs would replace by 3 different approaches
3.1. Set any TSLV values missing after the burn-in period to the burn-in period.  Keep all other TSLV values "as is".
3.2. Set any TSLV values missing after the burn-in period to the burn-in period.  Set the max TSLV to the burn-in period
3.3. Set any TSLV values missing after the burn-in period to the maximum observed TSLV.  Keep all other TSLV values "as is".
4. continue the same approaches 
5. merge the tslv values to the observed locations 

create a TSLV function
```{r tslv new}
tslv.PRT = function(grid_id, time, prev_data) {
  # grid_id: an integer representing a grid cell for which TSLV is to be calculated
  # time: a point in time for which TSLV is to be calculated
  # prev_data: a data.frame, with columns grid_id and t_. All values of t_ need not be before "time" as this will be filtered inside the function here. This data.frame should only contain points the animal actually visited, even if grid_id represents a random point.
  
  # Get all previous points that are recorded at grid_id
  prev_visits = prev_data[prev_data$grid_id == grid_id & prev_data$t_ < time, ]
  if (nrow(prev_visits) == 0) return(NA) # for now, keep this at NA. We will fix for the burnin later.
  
  last_visit = prev_visits[nrow(prev_visits), ] # get the final row of the data.frame
  
  # Returns a numeric value representing the time difference between last_visit and time
  return(as.numeric(difftime(time, last_visit$t_, units = "days")))
}
```

calculate TSLV for all values in the SSF data frame
```{r ssf tslv}
# apply the tslv function
ssfdat.wolf$tslv = sapply(X = 1:nrow(ssfdat.wolf), FUN = function(row) {
  tslv.PRT(ssfdat.wolf$grid_id[row], ssfdat.wolf$t2_[row], trk.wolf)
})

ssfdat.wolf.final = ssfdat.wolf
ssfdat.wolf %>% summary()

#just checking, can comment these out and it won't affect results
#write.csv(ssfdat.wolf, "ssfdat_wolf.csv")
#write.csv(trk.wolf, "trk_wolf.csv")
```

initial approach replace NA random points tslv to current time for the random points subtract to the initial temporal value ssfdat.wolf.final %>% dplyr::mutate(TSLV = ifelse(
  is.na(tslv),
  difftime(t2_, "2004-11-03 20:00:00.00 ", units = "hours"),
  tslv
))


Method 1
```{r method 1 burn in }
# method 1: Set any TSLV values missing after the burn-in period to the burn-in period.  Keep all other TSLV values "as is". (what Uli did and our initial approach w/ brown bear and cranes). This assumes if a cell was not visited during the burn-in period it was visited x days ago where x = burn-in period.

#30 days
wolf.burnin.1.30days <-
  ssfdat.wolf.final %>% dplyr::mutate(TSLV = ifelse(
    is.na(tslv) & t2_ > "2004-12-03 20:00:00.00",
    difftime("2004-12-03 20:00:00.00", "2004-11-03 20:00:00.00 ", units = "hours"),
    tslv
  ))

# 60 days
wolf.burnin.1.60days <-
  ssfdat.wolf.final %>% dplyr::mutate(TSLV = ifelse(
    is.na(tslv) & t2_ > "2005-01-03 20:00:00.00",
    difftime("2005-01-03 20:00:00.00", "2004-11-03 20:00:00.00 ", units = "hours"),
    tslv
  ))

summary(wolf.burnin.1.30days)
summary(wolf.burnin.1.60days)
```

```{r method 2}
# burn-in 30 days & 60 days

# Method 2: Set any TSLV values missing after the burn-in period to the burn-in period.  Set the max TSLV to the burn-in period. (my suggestion). This will treat all observations with TSLV >= burn-in period the same, but will only allow us to look at the effect of TSLV <= burn-in period.

#30 days
wolf.burnin.2.30days <- ssfdat.wolf.final %>% dplyr::mutate(TSLV = ifelse(
  is.na(tslv) & t2_ > "2004-12-03 20:00:00.00",
  difftime("2004-12-03 20:00:00.00", "2004-11-03 20:00:00.00 ", units = "hours"),
  ifelse(is.na(tslv),
         720,
         tslv))
)

# 60 days
wolf.burnin.2.60days <- ssfdat.wolf.final %>% dplyr::mutate(TSLV = ifelse(
  is.na(tslv) & t2_ > "2005-01-03 20:00:00.00",
  difftime("2005-01-03 20:00:00.00", "2004-11-03 20:00:00.00 ", units = "hours"),
  ifelse(is.na(tslv),
         1464,
         tslv))
)

summary(wolf.burnin.2.30days)
summary(wolf.burnin.2.60days)
```

```{r method 3}
# method 3: Set any TSLV values missing after the burn-in period to the maximum observed TSLV.  Keep all other TSLV values "as is". (what you did). This will lead to a lot of values set to the maximum since most grid cells are not visited during the burn-in period.

#30 days
wolf.burnin.3.30days <-
  ssfdat.wolf.final %>% dplyr::mutate(TSLV = ifelse(
    is.na(tslv) & t2_ > "2004-12-03 20:00:00.00",
    max(ssfdat.wolf.final %>% filter(!is.na(tslv)) %>% dplyr::select(tslv)),
    tslv
  ))

# 60 days
wolf.burnin.3.60days <-
  ssfdat.wolf.final %>% dplyr::mutate(TSLV = ifelse(
    is.na(tslv) & t2_ > "2005-01-03 20:00:00.00",
    max(ssfdat.wolf.final %>% filter(!is.na(tslv)) %>% dplyr::select(tslv)),
    tslv
  ))

summary(wolf.burnin.3.30days)
summary(wolf.burnin.3.60days)
```

```{r additional columns}
# create log(sl) and cos(ta) columns and convert the hour unit tslv to day unit
wolf.burnin.1.30days <-
  wolf.burnin.1.30days %>% mutate(log_sl_ = log(sl_),
                                  cos_ta_ = cos(ta_),
                                  TSLV = TSLV / 24)

wolf.burnin.1.60days <-
  wolf.burnin.1.60days %>% mutate(log_sl_ = log(sl_),
                                  cos_ta_ = cos(ta_),
                                  TSLV = TSLV / 24)


wolf.burnin.2.30days <-
  wolf.burnin.2.30days %>% mutate(log_sl_ = log(sl_),
                                  cos_ta_ = cos(ta_),
                                  TSLV = TSLV / 24)

wolf.burnin.2.60days <-
  wolf.burnin.2.60days %>% mutate(log_sl_ = log(sl_),
                                  cos_ta_ = cos(ta_),
                                  TSLV = TSLV / 24)

wolf.burnin.3.30days <-
  wolf.burnin.3.30days %>% mutate(log_sl_ = log(sl_),
                           cos_ta_ = cos(ta_),
                           TSLV = TSLV / 24)

wolf.burnin.3.60days <-
  wolf.burnin.3.60days %>% mutate(log_sl_ = log(sl_),
                           cos_ta_ = cos(ta_),
                           TSLV = TSLV / 24)
```

save the filtered data
```{r save the filtered data}
# burn in approach 1
## 30 days
write.csv(wolf.burnin.1.30days, file = here::here("data", "wolf.burnin.1.1.csv"))
write_rds(wolf.burnin.1.30days, file = here::here("data", "wolf.burnin.1.1.rds"))

## 60 days
write.csv(wolf.burnin.1.60days, file = here::here("data", "wolf.burnin.1.2.csv"))
write_rds(wolf.burnin.1.60days, file = here::here("data", "wolf.burnin.1.2.rds"))

# burn in approach 2 - 30 days and 60 days
## 30 days 
write.csv(wolf.burnin.2.30days, file = here::here("data", "wolf.burnin.2.1.csv"))
write_rds(wolf.burnin.2.30days, file = here::here("data", "wolf.burnin.2.1.rds"))

## 60 days 
write.csv(wolf.burnin.2.60days, file = here::here("data", "wolf.burnin.2.2.csv"))
write_rds(wolf.burnin.2.60days, file = here::here("data", "wolf.burnin.2.2.rds"))

# burn in approach 3 
## 30days
write.csv(wolf.burnin.3.30days, file = here::here("data", "wolf.burnin.3.1.csv"))
write_rds(wolf.burnin.3.30days, file = here::here("data", "wolf.burnin.3.1.rds"))

## 60 days
write.csv(wolf.burnin.3.60days, file = here::here("data", "wolf.burnin.3.2.csv"))
write_rds(wolf.burnin.3.60days, file = here::here("data", "wolf.burnin.3.2.rds"))
```

## Footer
```{r footer}
sessionInfo()
```